{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instala o módulo do PySpark\n",
        "!pip install -q pyspark==3.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF_za71QBmJ2",
        "outputId": "00b77f72-1e8e-40c1-ab73-96a6f2b84d6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 214.0 MB 8.1 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.0 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa os módulos\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext, SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "import datetime"
      ],
      "metadata": {
        "id": "PiLTl7TdBv5q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria a instância da sessão Spark\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "HWycemxJB4zw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria dataframe com dados para simular partições\n",
        "partition_data = [\n",
        "        (\"0\",\"partition=2022-08-20\")\n",
        "        ,(\"1\",\"partition=2019-07-01\")\n",
        "        ,(\"2\",\"partition=2019-06-24\")\n",
        "        ,(\"3\",\"partition=2019-08-24\")\n",
        "        ,(\"4\",\"partition=2022-07-17\")\n",
        "        ,(\"5\",\"partition=2022-07-18\")\n",
        "        ,(\"6\",\"partition=2022-07-19\")\n",
        "        ,(\"7\",\"partition=2022-07-20\")\n",
        "        ,(\"8\",\"partition=1987-02-25\")\n",
        "        ,(\"9\",\"partition=2022-08-30\")\n",
        "        ,(\"10\",\"partition=2022-09-11\")\n",
        "        ,(\"11\",\"partition=2022-09-09\")\n",
        "        ,(\"12\",\"partition=2022-09-12\")\n",
        "        ,(\"13\",\"partition=2022-09-13\")\n",
        "        ]\n",
        "dfPartition = spark.createDataFrame(data=partition_data\n",
        "                                    , schema=[\"id\",\"partition\"])"
      ],
      "metadata": {
        "id": "KS9L2LBaBeWW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "> Para as funções funcionarem em conjunto com o Hive, é necessário adaptar o código para buscar as partições da tabela desejada utilizando um código semelhante ao código abaixo:\n",
        "\n",
        "> `dataframe = spark.table(f\"show partitions {tabela}\")`\n",
        "---"
      ],
      "metadata": {
        "id": "Li59bxHHKYua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def busca_particao_proxima_tabela(dataframe, dt_referencia=None, diferenca_dias=0, formato_dt_origem='yyyy-MM-dd'):\n",
        "    '''\n",
        "        Função para retornar a partição de tabela Hive mais próxima da data informada.\n",
        "            Parâmetros:\n",
        "                - dataframe\n",
        "                    Tipo de dado: dataframe spark\n",
        "                - dt_referencia\n",
        "                    Tipo de dado: string\n",
        "                        Ex.: '2022-09-12'\n",
        "                - diferenca_dias\n",
        "                    Tipo de dado: int\n",
        "                        Ex.: 0\n",
        "                - formato_dt_origem\n",
        "                    Tipo de dado: string\n",
        "                        Ex.: 'yyyy-MM-dd'\n",
        "    '''\n",
        "\n",
        "    dt_part_referencia = dt_referencia or datetime.date.today().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    try:\n",
        "            \n",
        "        df_approx_partition = (\n",
        "            dataframe\n",
        "            .select(\n",
        "                F.regexp_extract('partition', r'([A-Za-z0-9_\\-]+)=([A-Za-z0-9_\\-]+)',2).alias('partition')\n",
        "            )\n",
        "            .withColumn('dt_partition', F.to_date('partition', formato_dt_origem))\n",
        "            .withColumn('datediff', F.datediff('dt_partition', F.lit(dt_part_referencia).cast('date')))\n",
        "            .where(F.col('datediff') <= diferenca_dias)\n",
        "            .orderBy(F.desc('datediff'))\n",
        "        )\n",
        "\n",
        "        retorno = df_approx_partition.first()['partition']\n",
        "\n",
        "    except IndexError:\n",
        "        retorno = None\n",
        "\n",
        "    return retorno"
      ],
      "metadata": {
        "id": "WDxJ8WmGBgUv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retorna a partição da tabela mais próxima da data '2022-09-08'\n",
        "busca_particao_proxima_tabela(dfPartition\n",
        "                              , dt_referencia='2022-09-08'\n",
        "                              , diferenca_dias=0\n",
        "                              , formato_dt_origem='yyyy-MM-dd')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "87Xt0_quM6Ha",
        "outputId": "16f92c9a-cac4-40f6-a923-7ac447b03100"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2022-08-30'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def busca_particao_tabela(dataframe, ordenacao='desc', posicao=0, formato_dt_origem='yyyy-MM-dd'):\n",
        "    '''\n",
        "        Função para retornar uma partição de tabela Hive. Também é possível retornar partições em outras posições.\n",
        "            Parâmetros:\n",
        "                - dataframe\n",
        "                    Tipo de dado: dataframe spark\n",
        "                - ordenacao\n",
        "                    Tipo de dado: string\n",
        "                        Ex.: 'desc'\n",
        "                - posicao\n",
        "                    Tipo de dado: int\n",
        "                        Ex.: \n",
        "                            0 -> Irá retornar a primeira posição do dataframe\n",
        "                            1 -> Irá retornar a segunda posição do dataframe\n",
        "                - formato_dt_origem\n",
        "                    Tipo de dado: string\n",
        "                        Ex.: 'yyyy-MM-dd'\n",
        "    '''\n",
        "    \n",
        "    try:\n",
        "\n",
        "        if ordenacao=='desc':\n",
        "\n",
        "            df_particao = (\n",
        "                dataframe\n",
        "                .select(\n",
        "                    F.regexp_extract('partition', r'([A-Za-z0-9_\\-]+)=([A-Za-z0-9_\\-]+)',2).alias('partition')\n",
        "                )\n",
        "                .withColumn('dt_partition', F.to_date('partition', formato_dt_origem))\n",
        "                .orderBy(F.desc('dt_partition'))\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            \n",
        "            df_particao = (\n",
        "                dataframe\n",
        "                .select(\n",
        "                    F.regexp_extract('partition', r'([A-Za-z0-9_\\-]+)=([A-Za-z0-9_\\-]+)',2).alias('partition')\n",
        "                )\n",
        "                .withColumn('dt_partition', F.to_date('partition', formato_dt_origem))\n",
        "                .orderBy(F.asc('dt_partition'))\n",
        "            )\n",
        "\n",
        "        retorno = df_particao.collect()[posicao]['partition']\n",
        "\n",
        "    except IndexError:\n",
        "        retorno = None\n",
        "\n",
        "    return retorno"
      ],
      "metadata": {
        "id": "wK-4V08nBjZD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retorna a partição mais recente da tabela\n",
        "busca_particao_tabela(dfPartition\n",
        "                      , ordenacao='desc'\n",
        "                      , posicao=0\n",
        "                      , formato_dt_origem='yyyy-MM-dd')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xot20H6JMy0S",
        "outputId": "1eb2c050-c55b-49bc-c75d-1e8771713656"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2022-09-13'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}